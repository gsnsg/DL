{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOviyK/r8YdnI7x4YAhzHAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainikhit2k/DL/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iKuoVQdt43D",
        "colab_type": "text"
      },
      "source": [
        "All of the architectures are from the following link:\n",
        "https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#e276"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sf7U0x0t6OZ",
        "colab_type": "text"
      },
      "source": [
        "<h1>Tensorflow implementation of AlexNet <h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCoHIw7ehHXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Flatten,Dense, Conv2D, MaxPool2D, ZeroPadding2D\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2wK_jqHhZkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "5663ef6c-5816-42d6-d44f-2a2abaeb730d"
      },
      "source": [
        "def conv_pool_block(x, n_filters, kernel_size, stride, padd=None, pool=True):\n",
        "\n",
        "  if padd:\n",
        "    x = ZeroPadding2D(padding=(padd,padd))(x)\n",
        "  x = Conv2D(n_filters, kernel_size=kernel_size, strides=stride, activation='relu')(x)\n",
        "  if pool:\n",
        "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "def AlexNet(input_shape=(227, 227, 3)):\n",
        "  inp_img = Input(shape=input_shape)\n",
        "  out = conv_pool_block(inp_img, 96, (11,11), (4,4))\n",
        "  out = conv_pool_block(out, 256, (5,5), (1,1), padd=2)\n",
        "  out = conv_pool_block(out, 384, (3,3),(1,1), padd=1, pool=False)\n",
        "  out = conv_pool_block(out, 384, (3,3),(1,1), padd=1, pool=False)\n",
        "  out = conv_pool_block(out, 256, (3,3), (1,1), padd=1, pool=False)\n",
        "  out = MaxPool2D(pool_size=(3,3), strides=(2, 2))(out)\n",
        "  out = Flatten()(out)\n",
        "  out = Dense(4096, activation='relu')(out)\n",
        "  out = Dense(4096, activation='relu')(out)\n",
        "  out = Dense(1000, activation='softmax')(out)\n",
        "  model = Model(inp_img, out)\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "\n",
        "alexNet = AlexNet()\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        (None, 227, 227, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPaddi (None, 31, 31, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPaddi (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPaddi (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPaddi (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 62,378,344\n",
            "Trainable params: 62,378,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey6dzmCfinCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMljUXx2IDOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvPool(nn.Module):\n",
        "  def __init__(self, in_channels, n_filters, kernel_size, stride, padd=0, pool=True):\n",
        "    super(ConvPool, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, n_filters, kernel_size, stride, padding=padd)\n",
        "    self.ReLU = nn.ReLU()\n",
        "    self.pool = pool\n",
        "    self.max_pool = nn.MaxPool2d((3,3), stride=2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.ReLU(self.conv(x)) \n",
        "    if self.pool:\n",
        "      x = self.max_pool(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# def ConvPool(in_channels, n_filters, kernel_size, stride, padd=0, pool=True):\n",
        "#   modules = []\n",
        "#   modules.append(nn.Conv2d(in_channels, n_filters, kernel_size, stride, padding=padd))\n",
        "#   modules.append(nn.ReLU(inplace=True))\n",
        "#   if pool:\n",
        "#     modules.append(nn.MaxPool2d((3,3), stride=2))\n",
        "  \n",
        "#   block = nn.Sequential(*modules)\n",
        "#   return block\n",
        "\n",
        "# test = ConvPool(3, 96, (11,11), 4)\n",
        "# summary(test, (3, 227, 227))\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uESZojqaJONp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AlexNet, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax()\n",
        "    self.conv1 = ConvPool(3, 96, (11,11), 4)\n",
        "    self.conv2 = ConvPool(96, 256, (5,5), 1, 2)\n",
        "    self.conv3 = nn.Conv2d(256, 384, (3,3), 1, 1)\n",
        "    self.conv4 = nn.Conv2d(384, 384, (3,3), 1, 1)\n",
        "    self.conv5 = ConvPool(384, 256, (3,3), 1, 1)\n",
        "    self.fc1 = nn.Linear(6*6*256, 4096)\n",
        "    self.fc2 = nn.Linear(4096, 4096)\n",
        "    self.fc3 = nn.Linear(4096, 1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(self.conv3(x))\n",
        "    x = self.relu(self.conv4(x))\n",
        "    x = self.conv5(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.softmax(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rkEBq39Ja8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "c3cade83-f47b-46fc-822b-d7881b86ba3e"
      },
      "source": [
        "net = AlexNet()\n",
        "summary(net, (3, 227, 227))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "          ConvPool-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-7          [-1, 256, 13, 13]               0\n",
            "          ConvPool-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-12          [-1, 384, 13, 13]               0\n",
            "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-14          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
            "         ConvPool-16            [-1, 256, 6, 6]               0\n",
            "           Linear-17                 [-1, 4096]      37,752,832\n",
            "             ReLU-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "          Softmax-22                 [-1, 1000]               0\n",
            "================================================================\n",
            "Total params: 62,378,344\n",
            "Trainable params: 62,378,344\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 11.93\n",
            "Params size (MB): 237.95\n",
            "Estimated Total Size (MB): 250.47\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2yCjobGJe50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}